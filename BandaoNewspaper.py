#coding=utf8
import os
import glob  
from PyPDF2 import PdfFileMerger
import random
import datetime
import requests
from lxml import etree

# 基本设置
timeout = 5
max_try_cnt = 20
# 代理 IP 池
proxy_pool = [["221.7.255.168", 8080, 10], ["221.7.255.168", 80, 10], ["119.28.26.57", 3128, 10], ["119.28.138.104", 3128, 10], ["120.92.88.202", 10000, 10], ["166.111.80.162", 3128, 10], ["119.27.177.169", 80, 10], ["140.143.96.216", 80, 10], ["47.88.189.75", 3128, 10], ["59.67.152.230", 3128, 10], ["211.159.177.212", 3128, 10], ["14.153.53.173", 3128, 10], ["47.88.35.91", 3128, 10], ["207.148.7.196", 3128, 10], ["192.240.120.138", 80, 10], ["120.77.254.116", 3128, 10], ["52.91.123.160", 3128, 10], ["188.43.15.105", 9090, 10], ["176.235.11.6", 8080, 10], ["113.200.56.13", 8010, 10], ["139.224.80.139", 3128, 10], ["118.212.137.135", 31288, 10], ["2.139.178.90", 3128, 10], ["5.9.78.28", 3128, 10], ["45.32.22.24", 3128, 10], ["121.196.211.154", 3128, 10], ["2.139.178.90", 3130, 10], ["188.166.99.252", 3128, 10], ["61.160.190.147", 8090, 10], ["194.182.74.51", 3128, 10], ["111.155.116.226", 8123, 10], ["61.160.190.146", 8090, 10], ["5.9.78.89", 3128, 10], ["163.172.217.103", 3128, 10], ["80.211.19.46", 3128, 10], ["142.44.240.50", 3128, 10], ["45.77.45.185", 3128, 10], ["111.230.165.16", 3128, 10], ["119.28.152.208", 80, 10], ["119.28.112.130", 8000, 10], ["182.253.201.76", 10000, 10], ["89.236.17.108", 3128, 10], ["139.59.21.37", 3128, 10], ["119.28.112.130", 3128, 10], ["61.216.1.23", 3128, 10], ["222.92.194.150", 80, 10], ["222.92.194.154", 80, 10], ["5.189.173.222", 3128, 10], ["47.96.23.239", 3128, 10], ["165.138.100.246", 8080, 10], ["202.116.160.104", 3128, 10], ["80.211.19.46", 80, 10], ["190.95.199.236", 8080, 10], ["194.182.74.7", 3128, 10], ["80.211.13.152", 3128, 10], ["66.70.147.195", 3128, 10], ["188.40.141.216", 3128, 10], ["139.59.35.10", 8080, 10], ["80.211.13.152", 8080, 10], ["194.182.74.151", 3128, 10], ["194.182.74.248", 3128, 10], ["14.118.254.16", 6666, 10], ["151.80.140.233", 54566, 9], ["192.240.120.122", 80, 9], ["61.144.205.247", 80, 9], ["45.76.234.157", 3128, 9], ["178.238.228.187", 9090, 9], ["198.58.122.39", 8080, 9], ["67.78.143.182", 8080, 9], ["117.71.150.221", 61234, 9], ["114.215.95.188", 3128, 9], ["1.58.173.99", 63000, 9], ["46.218.85.101", 3129, 9], ["179.191.233.238", 3128, 9], ["207.154.230.96", 3128, 9], ["185.82.212.95", 8080, 9], ["119.28.45.106", 3128, 9], ["194.182.74.160", 3128, 9], ["113.121.242.149", 61234, 9], ["111.155.116.227", 8123, 9], ["58.64.196.197", 3128, 9], ["218.106.205.145", 8080, 9], ["18.217.183.44", 3128, 9], ["149.202.0.60", 3128, 9], ["212.22.86.114", 3130, 9], ["183.63.254.253", 1080, 9], ["183.179.199.225", 8080, 9], ["137.74.168.174", 8080, 9], ["203.174.112.13", 3128, 9], ["104.131.94.221", 8080, 9], ["103.54.100.65", 8080, 9], ["101.37.79.125", 3128, 9], ["188.166.227.131", 8080, 9], ["152.101.74.81", 3128, 9], ["191.249.225.240", 8080, 9], ["156.67.221.110", 3128, 8], ["67.205.177.27", 8080, 8], ["165.227.37.246", 8080, 8], ["94.23.76.166", 3128, 8], ["117.71.133.192", 61234, 8], ["219.139.178.192", 61234, 8], ["107.182.236.62", 3128, 8], ["114.100.181.66", 61234, 8], ["27.44.162.176", 9999, 8], ["156.67.221.109", 3128, 8], ["125.118.247.125", 6666, 8], ["61.144.105.242", 9797, 8], ["103.228.112.66", 3128, 8], ["182.18.13.149", 53281, 8], ["201.130.208.154", 8080, 8], ["77.36.18.114", 3129, 8], ["60.255.186.169", 8888, 8], ["43.247.68.211", 3128, 7], ["13.59.54.80", 3128, 7], ["202.175.61.162", 8080, 7], ["59.32.37.246", 61234, 7], ["121.237.137.16", 3128, 7], ["185.145.202.171", 3128, 7], ["116.62.11.138", 3128, 7], ["35.227.26.224", 3128, 7], ["167.99.72.221", 8080, 7], ["110.154.73.129", 53281, 7], ["113.121.243.11", 61234, 7], ["112.140.187.82", 3128, 7], ["39.137.37.12", 80, 7], ["189.26.121.206", 3128, 7], ["180.168.210.132", 80, 7], ["67.205.160.67", 8080, 7], ["36.67.54.41", 8080, 7], ["58.87.87.142", 80, 7], ["213.142.149.4", 9090, 7], ["103.27.0.15", 3128, 7], ["221.217.50.72", 9000, 6], ["167.99.12.148", 8000, 6], ["121.69.3.102", 8080, 6], ["49.79.195.244", 61234, 6], ["115.208.120.92", 808, 6], ["39.134.108.89", 80, 6], ["200.29.191.151", 3128, 6], ["39.134.108.90", 80, 6], ["39.137.37.11", 80, 6], ["113.12.175.186", 9797, 6], ["39.137.37.10", 80, 6], ["39.137.37.8", 80, 6], ["39.137.37.9", 80, 6], ["120.92.117.94", 10000, 6], ["47.96.134.8", 8123, 6], ["39.134.108.71", 80, 6], ["207.154.245.20", 80, 6], ["188.166.226.134", 8080, 6], ["167.99.68.93", 8080, 6], ["116.228.236.219", 8080, 6], ["194.182.74.168", 3128, 6], ["220.191.100.124", 6666, 5], ["52.187.162.198", 3128, 5], ["119.28.5.254", 808, 5], ["124.67.10.134", 61234, 5], ["159.89.20.114", 8080, 5], ["39.134.153.26", 80, 5], ["49.79.194.188", 61234, 5], ["188.166.183.170", 8080, 5], ["139.59.240.30", 8080, 5], ["212.237.34.18", 8888, 5], ["39.134.108.92", 8080, 5], ["187.85.179.69", 3128, 5], ["118.114.77.47", 8080, 5], ["80.211.4.187", 8080, 5], ["112.248.24.20", 61234, 5], ["14.29.47.90", 3128, 5], ["112.248.17.187", 61234, 5], ["43.240.6.218", 53281, 5], ["178.32.214.3", 3128, 5], ["182.253.176.22", 8080, 5], ["138.68.140.197", 3128, 5], ["218.20.55.187", 9999, 5], ["218.106.98.166", 53281, 5], ["180.76.135.10", 3128, 5], ["118.178.227.171", 80, 5], ["14.153.53.137", 3128, 4], ["180.116.122.159", 6666, 4], ["113.105.203.116", 3128, 4], ["60.184.175.251", 3128, 4], ["167.99.2.17", 8080, 4], ["98.191.98.146", 3128, 4], ["31.182.52.156", 3129, 4], ["116.11.254.37", 80, 4], ["120.26.110.59", 8080, 4], ["175.162.79.221", 808, 4], ["115.46.97.115", 8123, 4], ["155.4.12.61", 8080, 4], ["181.30.101.242", 3128, 4], ["139.59.223.115", 8118, 4], ["183.207.194.221", 3128, 4], ["27.116.21.218", 3128, 4], ["67.205.174.194", 8080, 4], ["120.79.64.64", 80, 4], ["27.44.196.45", 9999, 4], ["122.72.18.34", 80, 3], ["167.99.2.17", 3128, 3], ["167.99.4.193", 8080, 3], ["159.65.24.96", 8080, 3], ["112.248.24.130", 61234, 3], ["198.199.69.204", 80, 3], ["113.121.240.18", 61234, 3], ["112.245.195.127", 61234, 3], ["217.75.204.6", 8080, 3], ["61.178.238.122", 63000, 3], ["211.147.67.150", 80, 3], ["144.76.76.25", 3128, 3], ["177.37.160.198", 3128, 3], ["14.118.253.135", 6666, 3], ["123.53.132.244", 22771, 3], ["149.56.109.203", 3128, 3], ["209.50.52.85", 3128, 3], ["139.129.166.68", 3128, 3], ["122.136.212.132", 53281, 3], ["113.65.20.144", 9999, 3], ["79.203.41.24", 8080, 3], ["47.52.33.216", 3128, 2], ["219.135.164.245", 3128, 2], ["159.65.184.229", 3128, 2], ["207.154.244.1", 80, 2], ["27.40.179.17", 61234, 2], ["124.160.71.118", 8081, 2], ["223.245.177.193", 61234, 2], ["182.39.34.246", 61234, 2], ["49.79.194.58", 61234, 2], ["167.99.4.193", 3128, 2], ["113.121.243.17", 61234, 2], ["128.199.146.81", 8080, 2], ["139.59.8.192", 8080, 2], ["182.39.41.125", 61234, 2], ["13.56.247.85", 3128, 2], ["218.56.132.157", 8080, 2], ["218.56.132.158", 8080, 2], ["218.56.132.154", 8080, 2], ["181.211.191.227", 8080, 2], ["80.211.231.52", 3128, 2], ["177.136.252.7", 3128, 2], ["103.228.117.244", 8080, 2], ["94.75.219.25", 3128, 1], ["139.59.240.151", 80, 1], ["223.245.180.249", 61234, 1], ["182.39.41.96", 61234, 1], ["2.178.255.157", 3128, 1], ["121.231.155.122", 6666, 1], ["120.92.119.187", 10000, 1], ["167.99.82.226", 8080, 1], ["222.185.3.120", 6666, 1], ["211.159.171.58", 80, 1], ["212.22.86.107", 3130, 1], ["220.249.185.178", 9999, 1], ["220.132.30.63", 3128, 1], ["103.6.4.3", 3128, 1], ["122.72.18.35", 80, 0], ["180.119.65.90", 3128, 0], ["139.224.24.26", 8888, 0], ["159.65.24.96", 3128, 0], ["120.236.142.103", 8888, 0], ["139.59.8.192", 80, 0], ["175.155.25.29", 1133, 0], ["163.172.220.221", 8888, 0], ["202.199.162.43", 808, 0], ["36.111.205.166", 80, 0], ["103.211.143.9", 80, 0], ["106.38.159.103", 8888, 0]]
headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36',
    'Host' : 'bddsb.bandao.cn',
    'Referer' : 'http://bddsb.bandao.cn/pc/bddsb/20180318/PageA01BC.htm',
    'Upgrade-Insecure-Requests' : '1',
}


def Parse(url,pattern):
    # 根据模式串 pattern 解析 url 页面源码（XPATH）
    # 设置代理IP，发送请求
    try_cnt = 0
    while True:
        try:
            # ip = proxyip.get()
            ip = random.sample(proxy_pool, 1)[0]
            proxies = {'http':'%s:%d'%(ip[0],ip[1])}
            response = requests.get(url, proxies=proxies, timeout=timeout, headers=headers)
            # response = requests.get(url, timeout=timeout)
        except Exception,e:
            print 'Request failed, retry!'
            print str(e)
            try_cnt += 1
            if try_cnt >= max_try_cnt:
                raise Exception, 'The request exceeds the number of attempts and the request is abandoned.'
        else:
            break
    # 解析
    html = response.content
    selector = etree.HTML(html)
    items = selector.xpath(pattern)
    return items

def download(url, file_path='tmp'):
    '''根据链接下载到本地同文件夹下'''
    try_cnt = 0
    while True:
        try:
            # ip = proxyip.get()
            ip = random.sample(proxy_pool, 1)[0]
            proxies = {'https':'%s:%d'%(ip[0],ip[1])}
            response = requests.get(url, proxies=proxies, timeout=timeout, headers=headers)
            # response = requests.get(url, timeout=timeout)
        except Exception,e:
            print 'Request failed, retry!'
            try_cnt += 1
            if try_cnt >= max_try_cnt:
                raise Exception, 'The request exceeds the number of attempts and the request is abandoned.'
        else:
            break
    # 解析
    fp = open(file_path, 'wb')
    fp.write(response.content)
    fp.close()



def getDate():
    '''获取前一天的日期'''
    now_time = datetime.datetime.now()
    yes_time = now_time + datetime.timedelta(days=-1)
    yes_time_nyr = yes_time.strftime('%Y%m%d')
    return yes_time_nyr



def SplicePDF(pdf_list, filename):
    '''拼接完整 pdf'''
    merger = PdfFileMerger()  
    for pdf in pdf_list:  
        merger.append(pdf)
    merger.write(filename)
    merger.close()  


# def SplicePDF(pdf_list, filename):
#     '''拼接完整 pdf'''
#     # 生成一个空白的pdf文件
#     pdfWriter = PyPDF2.PdfFileWriter()     

#     for pdf_name in pdf_list:
#         # 以只读方式依次打开pdf文件
#         pdf_fp = open(pdf_name,'rb')
#         print pdf_name
#         pdfReader = PyPDF2.PdfFileReader(pdf_fp, strict=False)
#         for page in range(pdfReader.getNumPages()):
#             # 将打开的pdf文件内容一页一页的复制到新建的空白pdf里
#             print page
#             pageObj = pdfReader.getPage(page)
#             pdfWriter.addPage(pageObj)   
#         pdf_fp.close() 

#     # 生成combine.pdf文件
#     pdfOutput = open(filename,'wb')     
#     # 将复制的内容全部写入combine.pdf
#     pdfWriter.write(pdfOutput)
#     pdfOutput.close()

def del_dir_tree(path):
    ''' 递归删除目录及其子目录,　子文件'''
    if os.path.isfile(path):
        try:
            os.remove(path)
        except Exception, e:
            print e
    elif os.path.isdir(path):
        for item in os.listdir(path):
            itempath = os.path.join(path, item)
            del_dir_tree(itempath)
        try:
            os.rmdir(path) # 删除空目录
        except Exception, e:
            print e

def main():
    # 获取基本信息
    date = getDate()
    script_dir = os.path.dirname(os.path.abspath(__file__))
    script_filename = __file__.split('\\')[-1].split('.')[0]
    tmp_dir = '%s\\%s'%(script_dir, script_filename + '_temp')

    # 创建临时文件夹，放置 pdf 单页
    print 'Creating a temporary folder...'
    if os.path.exists(tmp_dir):
        pass
        # raise Exception, '[ERROR] Temporary folder already exist!'
    else:
        os.mkdir(tmp_dir)

    # 获得报纸各版的 pdf 链接
    print 'Obtaining pdf links for each page of the newspaper...'
    per_page_list = []
    host = 'http://bddsb.bandao.cn/pc/bddsb'
    index_url = '%s/%s/PageArticleIndexBT.htm'%(host, date)
    # items = Parse(index_url, '//div[@class="ban"]//a[1]')
    items = Parse(index_url, '//div[@class="banmianlist_box"]/a[@href]')
    page_sum = len(items)
    print 'The latest newspaper(%s) is a total of %d pages...'%(date, page_sum)
    for item in items:
        # url = '%s/%s/%s'%(host, date, item.attrib['href'].strip('.'))
        paper_no = item.text.split('[')[-1].split(']')[0].strip()
        url = '%s/%s/%s.pdf'%(host, date, paper_no)
        print url
        per_page_list.append(url)


    # 下载报纸各版本 pdf
    print 'Downloading pdf of each page of newspaper...'
    pdf_list = []
    for i, page_url in enumerate(per_page_list):
        filename = page_url.split('/')[-1]
        file_path = '%s\\%s'%(tmp_dir, filename)
        pdf_list.append(file_path)
        print '[%d/%d] Downloading %s...'%(i+1, page_sum, filename)
        download(page_url, file_path)


    # 拼接完整 pdf
    print 'Splicing pdf...'
    full_pdf_filename = '%s\\%s_%s.pdf'%(script_dir, '半岛都市报'.decode('utf8'), date)
    SplicePDF(pdf_list, full_pdf_filename)

    # 删除临时目录
    print 'Deleting temporary directory...'
    if not os.path.exists(tmp_dir):
        raise Exception, '[ERROR] Temporary folder no longer exists!'    
    # 递归删除文件夹
    del_dir_tree(tmp_dir)


if __name__ == '__main__':
    # main()
    try:
        main()
    except Exception, e:
        print e
    os.system('pause')